{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Visualisation des erreurs des modèles\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Comparaison des prédictions vs réelles pour chaque modèle\n",
    "plt.figure(figsize=(14, 10))\n",
    "for idx, (model_name, model) in enumerate(models.items(), 1):\n",
    "    plt.subplot(3, 2, idx)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Tracer les erreurs (résidus)\n",
    "    residuals = y_test - y_pred\n",
    "    sns.histplot(residuals, kde=True, color='blue', bins=30)\n",
    "    plt.title(f\"Résidus - {model_name}\")\n",
    "    plt.xlabel(\"Erreur\")\n",
    "    plt.ylabel(\"Fréquence\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Visualisation des prédictions vs valeurs réelles\n",
    "plt.figure(figsize=(14, 10))\n",
    "for idx, (model_name, model) in enumerate(models.items(), 1):\n",
    "    plt.subplot(3, 2, idx)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Tracer les prédictions vs les vraies valeurs\n",
    "    plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r', label=\"Référence\")\n",
    "    plt.title(f\"{model_name} - Prédictions vs Réelles\")\n",
    "    plt.xlabel(\"Valeurs Réelles\")\n",
    "    plt.ylabel(\"Prédictions\")\n",
    "    plt.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Affichage des métriques de performance pour chaque modèle\n",
    "performance_metrics = pd.DataFrame(results).T\n",
    "performance_metrics = performance_metrics[['MAE', 'MSE', 'RMSE', 'R2']]\n",
    "print(\"\\nMétriques de performance des modèles de régression :\")\n",
    "print(performance_metrics)\n",
    "\n",
    "# 4. Analyser les biais potentiels (exemples spécifiques)\n",
    "# Afficher les 5 premières prédictions et leurs erreurs pour le modèle le mieux performant\n",
    "best_model_name = performance_metrics['R2'].idxmax()  # Le modèle avec le meilleur R2\n",
    "best_model = models[best_model_name]\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Erreurs pour le modèle avec le meilleur R2\n",
    "errors_best = y_test - y_pred_best\n",
    "predictions_vs_errors = pd.DataFrame({\n",
    "    'Valeur réelle': y_test,\n",
    "    'Prédiction': y_pred_best,\n",
    "    'Erreur': errors_best\n",
    "})\n",
    "\n",
    "print(f\"\\nErreurs pour le modèle {best_model_name}:\")\n",
    "print(predictions_vs_errors.head())\n",
    "\n",
    "# 5. Analyser l'importance des caractéristiques pour le RandomForest\n",
    "if 'Forêt Aléatoire' in models:\n",
    "    rf_model = models['Forêt Aléatoire']\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    feature_importance = rf_model.feature_importances_\n",
    "    features = X_train.columns\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': feature_importance\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nImportance des caractéristiques pour la Forêt Aléatoire :\")\n",
    "    print(feature_importance_df)\n",
    "    \n",
    "    # Visualisation de l'importance des caractéristiques\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
    "    plt.title('Importance des caractéristiques - Forêt Aléatoire')\n",
    "    plt.show()\n",
    "\n",
    "# 6. Conclusion générale de l'évaluation\n",
    "# Interprétation des performances globales des modèles\n",
    "best_model_overall = best_model_name\n",
    "best_r2 = performance_metrics.loc[best_model_overall, 'R2']\n",
    "print(f\"\\nLe meilleur modèle est : {best_model_overall} avec un R2 de {best_r2:.4f}.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
